{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf61c4b",
   "metadata": {},
   "source": [
    "# Programming Task Description\n",
    "\n",
    "## Programming Task: Implementing a Character-Level GPT Model\n",
    "\n",
    "### Introduction\n",
    "In this task, you will create a Python script using PyTorch to implement a simplified GPT (Generative Pre-trained Transformer) model for character-level language modeling. The model will be trained on the text in input.txt to predict the next character in a sequence and generate new text based on a given context. The architecture follows the decoder part of the transformer model from the \"Attention is All You Need\" paper by Vaswani et al., focusing on masked multi-head self-attention to ensure predictions depend only on previous positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537c2f6",
   "metadata": {},
   "source": [
    "## Task Description\n",
    "### Your goal is to write a Python jupyter notebook that:\n",
    "\n",
    "1. Reads and processes the text from input.txt.\n",
    "2. Implements a decoder-only transformer model with manual attention mechanisms.\n",
    "3. Trains the model on the processed data.\n",
    "4. Generates new text using the trained model.\n",
    "\n",
    "You will use PyTorch and implement the attention mechanism from scratch, following the decoder structure outlined in the \"Attention is All You Need\" paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df79368",
   "metadata": {},
   "source": [
    "### Step-by-step Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d36b1",
   "metadata": {},
   "source": [
    "1. Data Preparation\n",
    "* Read all text from input.txt using UTF-8 encoding.\n",
    "* Create a sorted list of unique characters (vocabulary) from the text.\n",
    "* Build two dictionaries:\n",
    "    * stoi: Maps characters to integers (e.g., 'a' -> 0).\n",
    "    * itos: Maps integers to characters (e.g., 0 -> 'a').\n",
    "* Define functions:\n",
    "    * encode(s): Converts a string to a list of integers using stoi.\n",
    "    * decode(l): Converts a list of integers to a string using itos.\n",
    "* Encode the entire text into a tensor of integers using torch.tensor.\n",
    "* Split the data: 90% for training, 10% for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37a3e46",
   "metadata": {},
   "source": [
    "2. Data Loading\n",
    "* Implement a function get_batch(split):\n",
    "    * Input: split is either 'train' or 'val'.\n",
    "    * Select the appropriate dataset (training or validation).\n",
    "    * Randomly sample batch_size starting indices, ensuring each sequence fits within block_size.\n",
    "* Return:\n",
    "    * x: A tensor of shape (batch_size, block_size) with input sequences.\n",
    "    * y: A tensor of shape (batch_size, block_size) with target sequences (shifted by one position).\n",
    "* Move tensors to the device (CPU or GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f100337",
   "metadata": {},
   "source": [
    "3. Model Architecture\n",
    "* Implement the following components in a decoder-only transformer:\n",
    "    * Embedding Layers:\n",
    "        * Token embedding: nn.Embedding(vocab_size, n_embd) for character indices.\n",
    "        * Position embedding: nn.Embedding(block_size, n_embd) for positions 0 to block_size-1.\n",
    "    * Transformer Blocks:\n",
    "        * Each block includes:\n",
    "            * Masked Multi-Head Self-Attention:\n",
    "                * Implement manually (do not use nn.MultiheadAttention).\n",
    "                * For each head:\n",
    "                    * Linear layers for queries (Q), keys (K), and values (V).\n",
    "                    * Scaled dot-product attention: attention = softmax((Q @ K.T) / sqrt(d_k)) @ V.\n",
    "                    * Mask future positions with a lower triangular matrix (e.g., tril) by setting future weights to -inf before softmax.\n",
    "                * Concatenate heads and apply a projection layer.\n",
    "            * Feed-Forward Network: nn.Linear(n_embd, 4 * n_embd) â†’ ReLU â†’ nn.Linear(4 * n_embd, n_embd).\n",
    "            * Layer Normalization: Apply nn.LayerNorm(n_embd) before each sub-layer (pre-norm).\n",
    "            * Residual Connections: Add input to output of each sub-layer.\n",
    "        * Use n_layer blocks in sequence.\n",
    "    * Final Layers:\n",
    "        * nn.LayerNorm(n_embd) for final normalization.\n",
    "        * nn.Linear(n_embd, vocab_size) to produce logits.\n",
    "* Define a GPTLanguageModel class with:\n",
    "    * forward(idx, targets=None): Computes logits and loss (if targets provided).\n",
    "    * generate(idx, max_new_tokens): Autoregressively generates new tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2098832e",
   "metadata": {},
   "source": [
    "4. Training\n",
    "* Use the AdamW optimizer with learning_rate = 3e-4.\n",
    "* Train for max_iters = 5000 iterations.\n",
    "* Estimate and print training and validation losses:\n",
    "* Compute loss using F.cross_entropy on flattened logits and targets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838a7a8",
   "metadata": {},
   "source": [
    "5. Text Generation\n",
    "* Implement generate(idx, max_new_tokens):\n",
    "    * Start with an initial context idx (shape (B, T)).\n",
    "    * For max_new_tokens steps:\n",
    "        * Crop idx to the last block_size tokens.\n",
    "        * Get logits from forward.\n",
    "        * Apply softmax to the last time stepâ€™s logits to get probabilities.\n",
    "        * Sample the next token using torch.multinomial.\n",
    "        * Append the sampled token to idx.\n",
    "    * Return the extended sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b8dab",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Use these values:\n",
    "\n",
    "* batch_size = 64\n",
    "* block_size = 256\n",
    "* n_embd = 384\n",
    "* n_head = 6\n",
    "* n_layer = 6\n",
    "* dropout = 0.2\n",
    "* learning_rate = 3e-4\n",
    "* max_iters = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1a954",
   "metadata": {},
   "source": [
    "### Understanding the Decoder\n",
    "The \"Attention is All You Need\" paper describes a transformer with an encoder and decoder. For this task, you focus on the decoder-only architecture used in GPT:\n",
    "\n",
    "* Masked Self-Attention: Ensures the model only attends to previous positions in the sequence, making it autoregressive. This is achieved by masking future tokens in the attention computation, as shown below:\n",
    "\n",
    "$Attention (Q, K, V) = softmax((Q@K.T)/sqrt(d_{k}) + mask) @V$ \n",
    "\n",
    "where $mask$ sets future positions to $-inf$\n",
    "\n",
    "* Decoder Role: In the original paper, the decoder generates output sequences while attending to the encoderâ€™s output. Here, without an encoder, it uses self-attention on the input sequence alone, predicting the next token step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33caf5",
   "metadata": {},
   "source": [
    "### Additional Notes\n",
    "* Manual Attention: Implement attention from scratch to understand its mechanics (no pre-built PyTorch modules).\n",
    "* Masking: Use a lower triangular matrix (e.g., torch.tril) to mask future positions.\n",
    "* Device Handling: Set device = 'cuda' if torch.cuda.is_available() else 'cpu' and move tensors/models accordingly.\n",
    "* Dropout: Apply nn.Dropout(dropout) in attention and feed-forward layers for regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0da406",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "A Python script that:\n",
    "* Implements all steps above.\n",
    "* Prints training and validation losses every 500/100? iterations (up to you).\n",
    "* Generates and prints a 500-character sample after training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b7b3ac",
   "metadata": {},
   "source": [
    "### Evaluation Criteria\n",
    "* Correct data preparation and batch loading.\n",
    "* Accurate implementation of the transformer model, especially masked self-attention.\n",
    "* Successful training with decreasing loss.\n",
    "* Generation of coherent (for character-level) text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe3f81-98ca-4d0f-9a3b-eaa0ba4abb75",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f01d92e3-7e1d-4f8a-8688-40681676013c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\scout\\code\\ai-project\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a462bb-a647-431c-95f9-6254d0042425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import random_split\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import random\n",
    "#import torchvision\n",
    "#import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "893adce7-5ba0-4305-b7ba-2d76e1324bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff3525c-9e62-4b99-a1fb-1859b0c1211b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42698f67-bbb7-419e-a704-59c33cf50922",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/input-2.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "sorted_chars = sorted(list(set(data)))\n",
    "sorted_str = \"\".join(sorted_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f0b4468-3829-42e5-b471-9eda58788378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'proceed any further, hear'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[25:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d764148a-7b84-490e-ac37-4e4b7c78a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(sorted_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2962a449-330a-42f2-bc6b-78b98b698767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self):\n",
    "        self.tokens: dict = {}\n",
    "        self.rev_tokens: dict = {}\n",
    "        self.idx: int = 0\n",
    "\n",
    "    def encode(self, chars: str):\n",
    "        result = []\n",
    "        for c in chars:\n",
    "            if c not in self.tokens.keys():\n",
    "                self.tokens[c] = self.idx\n",
    "                self.rev_tokens[self.idx] = c\n",
    "                self.idx += 1\n",
    "            result.append(self.tokens[c])\n",
    "        return result\n",
    "\n",
    "    def decode(self, nums: list[int]):\n",
    "        result = [self.rev_tokens[i] for i in nums]\n",
    "        return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99fd3d3c-7931-4800-bbe8-75a69d62da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64] \n",
      " \n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "encoded_str = tokenizer.encode(sorted_str)\n",
    "decoded_str = tokenizer.decode(encoded_str)\n",
    "\n",
    "print(encoded_str, \"\\n\", decoded_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b43ad3a-43d9-47e2-8d6b-d34bb137c0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String to Int:\n",
      " {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64} \n",
      "\n",
      "Int to String:\n",
      " {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}\n"
     ]
    }
   ],
   "source": [
    "stoi = {x: y for x, y in zip(sorted_str, encoded_str)}\n",
    "itos = {x: y for x, y in zip(encoded_str, sorted_str)}\n",
    "\n",
    "print(\"String to Int:\\n\", stoi, \"\\n\")\n",
    "print(\"Int to String:\\n\", itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeeb50ef-195b-479b-9101-2f2f84a8e682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56,  ..., 45,  8,  0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data = torch.tensor(tokenizer.encode(data))\n",
    "encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e613625-babb-4bb1-9195-1bcfd5ad8690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56,  ..., 43, 56, 43])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(encoded_data) * 0.9)\n",
    "val_size = len(encoded_data) - train_size\n",
    "\n",
    "train_data, val_data = encoded_data[:train_size], encoded_data[train_size + 1: len(encoded_data)]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8730d5-e257-4ff9-b913-144605da9653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "\n",
    "batch_size = 64\n",
    "block_size = 256\n",
    "context_win = 256\n",
    "n_embd = 384\n",
    "n_head = 6\n",
    "n_layer = 6\n",
    "dropout = 0.2\n",
    "learning_rate = 3e-4\n",
    "max_iters = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "218a0bce-2daf-4713-943f-49184686f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: str):\n",
    "    global train_data, val_data\n",
    "    global train_size, val_size\n",
    "    global block_size, batch_size, device\n",
    "\n",
    "    data = {\n",
    "        'train': train_data,\n",
    "        'test': val_data\n",
    "    }.get(split.lower(), None)\n",
    "\n",
    "    data_size = {\n",
    "        'train': train_size,\n",
    "        'test': val_size\n",
    "    }.get(split.lower(), None)\n",
    "\n",
    "    if data is None or data_size is None:\n",
    "        raise ValueError(f\"Invalid split: {split}\")\n",
    "    \n",
    "    start_indices = [random.randint(0, data_size - block_size - 1) for _ in range(batch_size)]\n",
    "\n",
    "    x_list, y_list = [], []\n",
    "\n",
    "    while len(x_list) < batch_size:\n",
    "        idx = random.randint(0, data_size - block_size - 1)\n",
    "\n",
    "        x = data[idx: idx + block_size]\n",
    "        y = data[idx + 1: idx + block_size + 1]\n",
    "\n",
    "        if len(x) == len(y):\n",
    "            x_list.append(x.unsqueeze(0))\n",
    "            y_list.append(y.unsqueeze(0))\n",
    "\n",
    "    x_batch = torch.cat(x_list, dim=0).to(device)\n",
    "    y_batch = torch.cat(y_list, dim=0).to(device)\n",
    "\n",
    "    return (x_batch, y_batch)\n",
    "        \n",
    "train_xbatch, train_ybatch = get_batch('train')\n",
    "trainT, trainB = train_xbatch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01802210-5fd5-4fbd-a1c8-1010385b0da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 256])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xbatch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f8f16-c830-4e33-bbd0-78e80c2b1b27",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11e821e-3091-481a-81bd-94a6c3e5d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, n_embd: int, head_size: int, block_size: int, dropout: int):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_embd, head_size)\n",
    "        self.key = nn.Linear(n_embd, head_size)\n",
    "        self.value = nn.Linear(n_embd, head_size)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))           \n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, C = x.shape\n",
    "\n",
    "        K = self.key(x)\n",
    "        Q = self.query(x)\n",
    "        d_k = K.shape[-1]\n",
    "        # (1, T, T) -> (B, T, T)\n",
    "\n",
    "        weights = Q @ K.transpose(-2, -1) * d_k ** -0.5\n",
    "\n",
    "        #mask = self.tril[:T, :T].unsqueeze(0).expand(B, -1, -1).to(x.device)\n",
    "        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "\n",
    "        V = self.value(x)\n",
    "        out = weights @ V\n",
    "        return out\n",
    "        \n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, head_size, block_size, n_embd, n_head, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(n_embd, head_size, block_size, dropout) for _ in range(n_head)])\n",
    "        self.projection = nn.Linear(n_head * head_size, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        cat_heads = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.projection(cat_heads)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "# good\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(n_embd, 4 * n_embd)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(4 * n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.dropout(out)\n",
    "        return out\n",
    "\n",
    "# good\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, n_embd, n_head, dropout):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.attention = MultiHeadAttention(\n",
    "            vocab_size = vocab_size,\n",
    "            head_size = head_size,\n",
    "            block_size = block_size,\n",
    "            n_embd = n_embd,\n",
    "            n_head = n_head,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        self.feed_forward = FeedForward(n_embd, dropout)\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(n_embd)\n",
    "        self.norm2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # original input are added back intentionally as residuals\n",
    "        x = x + self.attention(self.norm1(x))\n",
    "        x = x + self.feed_forward(self.norm2(x))\n",
    "        return x\n",
    "    \n",
    "\n",
    "class GPTLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, block_size, n_embd, n_head, n_layer, dropout, device):        \n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.device = device\n",
    "\n",
    "        self.token_embd = nn.Embedding(vocab_size, n_embd)\n",
    "        self.pos_embd = nn.Embedding(block_size, n_embd)\n",
    "        \n",
    "        self.blocks = nn.Sequential(*[\n",
    "            Block(vocab_size, block_size, n_embd, n_head, dropout) for _ in range(n_layer)\n",
    "        ])\n",
    "        \n",
    "        self.norm = nn.LayerNorm(n_embd)\n",
    "        self.out = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, idx: torch.Tensor, targets: Optional[torch.Tensor] = None) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        B, T = idx.shape\n",
    "\n",
    "        tk_embedding = self.token_embd(idx)\n",
    "        pos_embedding = self.pos_embd(torch.arange(T, device=self.device))\n",
    "\n",
    "        x = tk_embedding + pos_embedding\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        logits = self.out(x)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B * T, C)\n",
    "            targets = targets.view(B * T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx: torch.Tensor, max_new_tokens: int) -> torch.Tensor:\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to last block_size tokens\n",
    "            crop_input = idx[:, -self.block_size:]\n",
    "\n",
    "            # get logits from forward\n",
    "            logits, _ = self(crop_input)\n",
    "            logits = logits[:, -1, :]\n",
    "\n",
    "            # apply softmax to the last time step's logits\n",
    "            prob = F.softmax(logits, dim=-1)\n",
    "\n",
    "            # sample next token using torch.multinomial\n",
    "            next_idx = torch.multinomial(prob, num_samples=1)\n",
    "\n",
    "            # append sampled token to idx\n",
    "            idx = torch.cat((idx, next_idx), dim=1)\n",
    "        return idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b254213-bee0-4cf1-8bbc-abeb55cceb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(vocab_size, block_size, n_embd, n_head, n_layer, dropout, device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52044d9f-69b4-4e33-8991-dda81918ff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000]: Train Loss: 4.3535 | Val Loss: 3.6492\n",
      "Epoch [501/5000]: Train Loss: 1.9603 | Val Loss: 1.9814\n",
      "Epoch [1001/5000]: Train Loss: 1.6112 | Val Loss: 1.7435\n",
      "Epoch [1501/5000]: Train Loss: 1.4827 | Val Loss: 1.6307\n",
      "Epoch [2001/5000]: Train Loss: 1.3974 | Val Loss: 1.6032\n",
      "Epoch [2501/5000]: Train Loss: 1.3400 | Val Loss: 1.5068\n",
      "Epoch [3001/5000]: Train Loss: 1.2579 | Val Loss: 1.4978\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 256 but got size 255 for tensor number 33 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m model.eval()\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     val_x, val_y = \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtest\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     _, val_loss = model(val_x, val_y)\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[32m500\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mget_batch\u001b[39m\u001b[34m(split)\u001b[39m\n\u001b[32m     27\u001b[39m     y_list.append(y.unsqueeze(\u001b[32m0\u001b[39m))\n\u001b[32m     29\u001b[39m x_batch = torch.cat(x_list, dim=\u001b[32m0\u001b[39m).to(device)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m y_batch = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (x_batch, y_batch)\n",
      "\u001b[31mRuntimeError\u001b[39m: Sizes of tensors must match except in dimension 0. Expected size 256 but got size 255 for tensor number 33 in the list."
     ]
    }
   ],
   "source": [
    "for epoch in range(max_iters):\n",
    "    x, y = get_batch('train')\n",
    "\n",
    "    model.train()\n",
    "    x.shape\n",
    "    outputs, loss = model(x, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_x, val_y = get_batch('test')\n",
    "        _, val_loss = model(val_x, val_y)\n",
    "    if epoch % 500 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{max_iters}]: Train Loss: {loss.item():.4f} | Val Loss: {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3434a84f-a0d5-4347-95c8-442f9be0b2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once, let's for the duke?\n",
      "\n",
      "First Officer:\n",
      "And, sweet there little Romans: I will not lie\n",
      "Thumps in their shouldst, repent your brother pens!\n",
      "All my if you now that I have much heighness,\n",
      "And said with spreadus both to them alone,\n",
      "And I'll betire you him for his head? That an odds be\n",
      "That hope-foots death youths and gracel pardon pack\n",
      "The His lawful company his life-pleading bosom,\n",
      "Since you callst him home to pardon. What news leaves,\n",
      "Thou hast no most nothly forfeit, you must I do\n",
      "Lookabour the bet\n"
     ]
    }
   ],
   "source": [
    "testing_input = \"Once\"\n",
    "encoded_testing_input = tokenizer.encode(testing_input)\n",
    "\n",
    "ti_tensor = torch.tensor(encoded_testing_input, dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "ti_tokens = model.generate(ti_tensor, 500)[0].tolist()\n",
    "\n",
    "val_gen = tokenizer.decode(ti_tokens)\n",
    "print(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69ceb01e-0601-41ea-8ecc-019b264787b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "torch.save(model.state_dict(), 'gpt-1_saved.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af4a236-062a-4366-a7e4-279e013066ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
